{"batch_size": 300, "epochs": 50, "learning_rate": 0.001, "optimizer": "adam", "hidden_layers": 2, "dropout": 0.2, "hidden_act": "tanh", "output_act": "relu", "scaling": 0.5}